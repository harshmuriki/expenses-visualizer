# ====================================
# LLM PROVIDER CONFIGURATION
# ====================================
# IMPORTANT: You can now use local LLMs or cloud providers!
# See LLM_SETUP_GUIDE.md for detailed setup instructions

# Provider type (required)
# Options: openai, ollama, lmstudio, anthropic, custom
LLM_PROVIDER=openai

# Model name (required)
# OpenAI: gpt-4o-mini, gpt-4, gpt-3.5-turbo
# Ollama: llama3.2, mistral, codellama, gemma2
# Anthropic: claude-3-5-sonnet-20241022, claude-3-haiku-20240307
# LM Studio: local-model (or your model name)
LLM_MODEL=gpt-4o-mini

# Temperature (optional, default: 0.2)
# Range: 0-2 (lower = more deterministic, higher = more creative)
LLM_TEMPERATURE=0.2

# Max tokens (optional, default: 16000 for most, 4096 for Anthropic)
LLM_MAX_TOKENS=16000

# ====================================
# OPENAI CONFIGURATION
# ====================================
# Get your API key from: https://platform.openai.com
OPENAI_KEY=sk-your-openai-api-key-here

# ====================================
# OLLAMA CONFIGURATION (Local, Free)
# ====================================
# Install Ollama from: https://ollama.com
# Then run: ollama pull llama3.2
OLLAMA_BASE_URL=http://localhost:11434

# ====================================
# LM STUDIO CONFIGURATION (Local, Free)
# ====================================
# Install LM Studio from: https://lmstudio.ai
# Start the local server in LM Studio
LMSTUDIO_BASE_URL=http://localhost:1234/v1

# ====================================
# ANTHROPIC CONFIGURATION
# ====================================
# Get your API key from: https://console.anthropic.com
ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here

# ====================================
# CUSTOM PROVIDER CONFIGURATION
# ====================================
# For any OpenAI-compatible API endpoint
CUSTOM_LLM_BASE_URL=https://your-api.com/v1
CUSTOM_LLM_API_KEY=your-custom-api-key  # Optional

# ====================================
# AWS LAMBDA (for PDF processing)
# ====================================
AWS_LAMBDA_ENDPOINT=your-lambda-endpoint-url

# ====================================
# BANK ACCOUNT INTEGRATION
# ====================================
# Choose your bank connection provider
# Options: local, plaid
# - local: CSV/PDF upload only (free, no setup required)
# - plaid: Full-featured bank integration (https://plaid.com)
BANK_PROVIDER=local

# ====================================
# PLAID CONFIGURATION
# ====================================
# Sign up at: https://plaid.com
PLAID_CLIENT_ID=your-plaid-client-id
PLAID_SECRET=your-plaid-secret
PLAID_ENV=sandbox  # or "development" or "production"

# ====================================
# FIREBASE CONFIGURATION
# ====================================
NEXT_PUBLIC_FIREBASE_API_KEY=your-firebase-api-key
NEXT_PUBLIC_FIREBASE_AUTH_DOMAIN=your-project.firebaseapp.com
NEXT_PUBLIC_FIREBASE_PROJECT_ID=your-project-id
NEXT_PUBLIC_FIREBASE_STORAGE_BUCKET=your-project.appspot.com
NEXT_PUBLIC_FIREBASE_MESSAGING_SENDER_ID=your-sender-id
NEXT_PUBLIC_FIREBASE_APP_ID=your-app-id
NEXT_PUBLIC_FIREBASE_MEASUREMENT_ID=your-measurement-id

# ====================================
# NEXTAUTH CONFIGURATION
# ====================================
NEXTAUTH_URL=http://localhost:3000
NEXTAUTH_SECRET=your-nextauth-secret-key

# ====================================
# SECURE TOKEN STORAGE (for Plaid)
# ====================================
# Generate a secure 32-byte key:
# node -e "console.log(require('crypto').randomBytes(32).toString('base64'))"
TOKEN_STORE_KEY=your-32-byte-base64-encoded-key

# ====================================
# OPTIONAL: DEBUG MODE
# ====================================
NEXT_PUBLIC_DEBUG=false
